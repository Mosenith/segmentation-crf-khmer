{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CRF-Khmer-Segmnt_Report.ipynb","provenance":[{"file_id":"1XszkzBKpuLsi4lsfaabEGa2vjPfsXy7Y","timestamp":1576693367246}],"collapsed_sections":["SXLgg7z5HBjJ","BpCLCpzfIVDW","xZFJSSHDIgKw","BpAAtNNTMJ4V","ILBGp8yspB_y"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gFXe9fPQL_Z_","colab_type":"text"},"source":["# Building Khmer Word Segmentation using Conditional Random Fields\n","This notebook contains the complete code that can be run to see the results as part of the approach to make this a reproducable research. Instruction is included on how to setup and run in Google Colab or any other python notebook compatible environments.\n","\n","This notebook conains two sections. \n","1. **Report**:  covers the report potion of this study which describe the approach, the algorithm and the results.\n","1. **Code**: shows the code which detail  the setup so you can follow along and see the excution results. You can execute the code in this Python notebook directly from your browser when setup to use Google Colab or other compatible systems. See implementation notebook \"CRF-Khmer-Segmentation.ipynb\".\n","\n","Expand each section and subsection to see detail.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SXLgg7z5HBjJ","colab_type":"text"},"source":["# Report"]},{"cell_type":"markdown","metadata":{"id":"MsVkt_QYMdRC","colab_type":"text"},"source":["## Abstract"]},{"cell_type":"markdown","metadata":{"id":"A9ZHnABPZW0H","colab_type":"text"},"source":["The motivation for this study is to look at different implementation approaches of Conditional Random Fields (CRF) to segment Khmer document which showed in earlier paper by Vichet Chea et al. (2015) to have a very high accuracy.\n","\n","We first describe the approach to gather training data from Khmer news site and save them to Github to make the corpus available for future study. The data is parsed using existing tool avaiable by the author above. This save us times from manually segmented the text.\n","\n","Then we explore the different features to be used in CRF and its performances. We also compare two different approaches of using a character based and Khmer character cluster (KCC) based. This implimentation with KCC approach shows an accuracy of 99.7% F-score comparable to performance showed 98.5% in earlier paper.\n"]},{"cell_type":"markdown","metadata":{"id":"r2US1AjQT3j1","colab_type":"text"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"-N-FMBr0T59N","colab_type":"text"},"source":["Khmer language (Cambodian) is written without spaces between words like Thai or Chinese writing system. Khmer may have spaces between phrases to indicate pauses but not specificaly between words. For native speaker, it is easy to discern words from the long sequences of characters. It is a challege to teach computer to recognize words with standard program technique since it is difficult to program specific logic to describe how to separate words.\n","\n","Since they are from different sources/sites, the format in term of how the text is formatted with invisible spaces are not consistent. \n","\n","We created this series of of blog post as an introduction on different approaches to word sgementation: https://medium.com/@phylypo/segmentation-of-khmer-text-using-conditional-random-fields-3a2d4d73956a.\n","\n","The Conditional Random Field (CRF) has several advantages compare to ngrams, MEMM for sequence related problems. We use this approach to find the most probable sequences of labels for a given sequences of characters seen in the training data."]},{"cell_type":"markdown","metadata":{"id":"Eelu9kDtU_F6","colab_type":"text"},"source":["### Overview\n","The general idea is to use CRF to learn how to segment Khmer text based on our training data.\n","First we get a list of Khmer articles, then created a segmented version which contain spaces between each word. Then create a format that the algorithm can learn from. \n","\n","For example, the sentence: ```This is a test.```\n","becomes:\n","```\n","T h i s i s a t e s t .\n","1 0 0 0 1 0 1 1 0 0 0 1\n","```\n","The label 1 indicates  that the corresponding character is the beginning of the word. The goal is for the algorithm to learn the feature and able to predict \"0\" or \"1\" on other sentences. \n","For example, if we passed in: ```Whatisthis?```\n","The correct prediction would be:\n","```\n","W h a t i s t h i s ?\n","1 0 0 0 1 0 1 0 0 0 1\n","```"]},{"cell_type":"markdown","metadata":{"id":"_h7Ka9PyZdqB","colab_type":"text"},"source":["## Tools\n","\n","We are not going to implement CRF algorithm from scratch but rather use existing tools or libraries. There are several popular CRF toolkits:\n","\n","- http://www.chokkan.org/software/crfsuite/: A fast implementation of Conditional Random Fields (CRFs)\n","- https://taku910.github.io/crfpp/ CRF++: Yet Another CRF toolkit\n","\n","Several Python libraries provide support to CRFsuite, including ***python-crfsuite*** and ***sklearn-crfsuite***. We try both and they have similiar performance, but we prefer the ***sklearn-crfsuite*** since it has similar sklearn usage format.\n","\n","CRF++ is a command line interface with features needed to be set in files and training data and output wrote to files. That was used by the Niptic Khmer Segmentations paper.\n","\n","Other CRF implementations include:\n","\n","- https://wapiti.limsi.fr/ : Wapiti - A simple and fast discriminative sequence labelling toolkit\n","- http://mallet.cs.umass.edu/ : MALLET includes tools for sequence tagging\n","- http://mallet.cs.umass.edu/grmm/general_crfs.php : General CRFs in GRMM\n","- http://flexcrfs.sourceforge.net/ : FlexCRFs -- Flexible Conditional Random Fields\n","\n","The tool we use to segment our training data is from Niptict Khmer Segmentation tool using CRF: https://niptict.edu.kh/khmer-word-segmentation-tool/."]},{"cell_type":"markdown","metadata":{"id":"BpCLCpzfIVDW","colab_type":"text"},"source":["## Training Dataset"]},{"cell_type":"markdown","metadata":{"id":"tdD81HBUZmGb","colab_type":"text"},"source":["To get training data, we need a fairly large corpus for training. This data need to consist of segmented words that can be used for training.\n","\n","We have crawled data on publicly avaible Khmer websites mainly news related.These data contain different categories like Cambodian related news, international, technologies and others.\n","\n","Thanks to [niptict](https://niptict.edu.kh) which provide a segmentation tool with very good accuracy, we are able to use it to format our training data. Instead of hand segment these data or use the existing segmentation in the data with non-zero space which are not reliable, we just pass the text to this tool to segment and save the output. This saved us a lot of time and efforts.\n","\n","Then we look at the output can hand corrected a subset of the articles. The correction is saved into our code as string substitution so we can apply them to all of the articles. This ensures that our corrections is consistent with all of the articles. The new result will be used as our training data set.\n","\n","The data can be found in Github here:\n","https://github.com/phylypo/segmentation-crf-khmer/tree/master/data.\n","\n","We have combined the downloadable files into different batch size (100, 500, 1000, 5000, and 10000 articles). Each batch is compressed to save space. This notebook will show how to download and decompressed the files for the training.\n","\n","### File name format\n","The file name format starts with a unique 6 digit number as id, then follow by '_seg' or '_orig' to indicate original text or segmented text. Some new set of files has '_200b' in the file name to indicate that we are using \\u200b unicode character as a separator rather than space. This new approach distinguish existing space that we don't need to predict useful for non-Khmer text.\n","\n","Here are some examples:\n","- 451807_seg_200b.txt : segmented text using 200b character\n","- 451807_orig.txt : original text\n","- 123456_seg.txt : old format segmented text using space (will not use this)."]},{"cell_type":"markdown","metadata":{"id":"jIUrOhPtlLht","colab_type":"text"},"source":["## Approaches to Khmer Segmentation with CRF\n","The goal is to train Khmer word segmentation using Conditional Random Fields (CRF) which was implemented in the paper [1] showing 0.99 F-score. We compare the different implimentation approaches:\n","1. character based vs. Khmer Characters Cluster (KCC)\n","1. different ngram length features\n","1. CRF parameters tuning\n","\n","We will detail the our approach to generating the training data, clean up the train data, generate the needed featrues for the algorithm, run and fine tune the algorithm and then measure the result.\n","\n","#### May need to delete the following\n","\n","The general idea is to predict if a given letter is the start of a word from a given Khmer text.\n","\n","Fo example if we were given: <pre>This is a test.</pre>\n","\n","First we remove the space and label the next character with 1 and the rest with zero. Then label as:\n","<pre>\n","Thisisatest.\n","100010110001\n","</pre>\n","where value 1 is for the char that will start as a word. The goal for the algorithm is to correctly guest where the value 1 will be given a string of characters in a sentence."]},{"cell_type":"markdown","metadata":{"id":"lj08y2TgbiqU","colab_type":"text"},"source":["## Features Engineering"]},{"cell_type":"markdown","metadata":{"id":"dS3Di9ukIPbg","colab_type":"text"},"source":["In this supervised machine learning algorithm, we need to create features so the algorithm can learn from. Fortunately, Linear chain CRF can take all kind of features without having to worry about feature correlation as in Naive Bayes or scaling.\n","\n","So in a way, creating feature is fairly simple. But we need to make sure those features contribute to the performance of the algorithm.\n","\n","We will cover several approaches:\n","\n","* different ngram size\n","* different features (char type, char count)\n","* type of chars/kcc\n","\n","Note: Python CRFsuite supports for features encoded in list or dictionary. It didn't make any differences but shorten the key, save lots of memory form \"char\" to \"c\"."]},{"cell_type":"markdown","metadata":{"id":"d_YvTKH5s-_b","colab_type":"text"},"source":["First let's look at the features used by Vichet Chea et. al. paper. For each character, the paper identifies 10 different type of characters. These tags are consonant, vowel, independence vowel, upper sign, Atak number, lunar number, subscript, sentence sign, no space (numbers), and unknown.\n","\n","\n","Here are the tags and list of characters:\n","\n","![tags used in Vichet Chea et. al. paper](https://cdn-images-1.medium.com/max/800/1*zzeP6cAgcsFc8vKDaIU9iQ.png)\n","\n","The label that tags the character \n","Tags:\n","\n","![label tags in Vichet Chea et. al. paper](https://cdn-images-1.medium.com/max/800/1*k6cMZm2cbPv_ll62fsDQvA.png)"]},{"cell_type":"markdown","metadata":{"id":"tWjxDIzyvwxA","colab_type":"text"},"source":["*** may need to remove this section ***\n","What is a word?\n","This in itself is a difficult thing to do. As native speaker, I have difficulty discerning a series of text as a compound word or not. \n","Let's look at Chuon Nath dictionary first: has 17,664 head words\n"," 18,947 entries with 17,664 head words. (each word may have multiple entries/definitions)\n","Keyword:\n","\n","\n","Compound Word\n","Prefix:\n","កតញ្ញូ vs អកតញ្ញូ (both words appear in dict) \n","សំពះ (កិ.) ការ​សំពះ (ន.) (later not in dict) --without 200b ការសំពះ\n","ការ = សំពះ (កិ.) ការ​សំពះ (ន.) ជាដើម ។ \n","\n","Suffix:\n","\n","We consider this as one word. For our context, we going to consider compound word as one word.  \n","Name: អកយំ ឈ្មោះ​បទ​ភ្លេង​មួយ​ប្រភេទ sad melody used in classical Cambodian music\n","អកអំបុក name of a ceremony\n","Cambodian-English Dictionary by Robert K. Headley 23,967 head word 33,543 sub-entries (word/phrase that contains the head word)\n","Cambodian Red Cross: កាកបាទក្រហមកម្ពុជា\n","( https://www.redcross.org.kh)\n","CRF can address long series:\n","ខុំញ ចង់ឱយ < អនក􀇒􀆎 ប់ > យល់ ពី ប􀈦􀆟 េនះ\n","I want the listener to understand this problem\n","\n","\"listener\" vs \"you to listen\":"]},{"cell_type":"markdown","metadata":{"id":"uXDUUbu0UWjT","colab_type":"text"},"source":["Here is our example features with character approach:\n","\n","<pre>តើអ្នកឈ្មោះអ្វី?</pre> (translated as \"What is your name?\")\n"," \n","\n","| char | type | label | segmented word |\n","|---------|---------|:--------:| :---: | \n","| ត   | C   | 1 | តើ\n","| ⁣ើ   | V  | 0 |\n","| អ   | C   | 1 | ⁣អ្នក\n","| ◌្   | S   | 0| \n","| ន   | C   | 0 |\n","| ក   | C   | 0 |\n","| ឈ | C   | 1 | ⁣ឈ្មោះ\n","| ◌្   | S | 0 |\n","| ម   | C   | 0 |\n","| ោ | V  |  0 |\n","|◌ះ   | V   | 0 |\n","| អ   | V   | 1 | ⁣អ្វី\n","|  ្  | S  | 0 |\n","|  វ  | C   | 0 |\n","|  ី  | V   | 0 |\n","|  ?  | O   | 1 | ⁣?\n","\n","\n","\n","\n","\n","Note on some differences to the implimentation in CRF paper:\n","1. label at ending instead of beginning -- just preference\n","2. type combine -- on consonant (didn't see the value of the differences)\n","3. not doing any tags (2 tags, 5 tags)\n"]},{"cell_type":"markdown","metadata":{"id":"yeI8z8s1dsD6","colab_type":"text"},"source":["Notes on some of the differences to the CRF paper:\n","* instead of end of word, we use beginning of the word\n","* type is slighly differences\n","* Use ngram characters (not sure if this was implemented in the paper)\n","\n","For KCC:\n","- type would be: K=Khmer text (contain consonant/vowels), N:number, E=Non-khmer, U:unknown"]},{"cell_type":"markdown","metadata":{"id":"2HYbXvqCh2wO","colab_type":"text"},"source":["### KCC Rules\n","\n","This is Khmer Character Cluster (KCC) rule in BNF format:\n","\n",">  <C|I> + [<Robat | Regshift>] + {COEUNG + <C + [Regshift] | I + [Regshift]>} + [[<ZWJ|ZWNJ>] +\n","V] + {S} + [ZWJ + COEUNG + <C | I>]\n","\n","\n","| Symbols | Meaning |\n","| -- | --- |\n","| {} | Zero to two occurrences\n","| [ ] | Zero to one occurrences\n","| <x \\| y> | The choice of x or y |\n","| C | Consonant\n","| I |  Independent vowel\n","| COEUNG | The COEUNG character (\\u 17D2)\n","| V | Vowel\n","| Regshift |  Registry shifter\n","| S | Various sign\n","| ZWNJ |  ZERO WIDTH NON-JOINERS\n","| ZWJ | ZERO WIDTH JOINERS\n","| ROBAT | The Robat sign (\\u 17CC) \n","\n","Source: [Detection and Correction of Homophonous Error Word for Khmer Language](http://ww.panl10n.net/english/outputs/Working%20Papers/Cambodia/Microsoft%20Word%20-%204_E_N_248.pdf)\n","    \n","Here is an example: \n","\n","Text: សាស្ត្រា​ត្រីនេត្រ \n","\n","Word: សាស្ត្រា - ត្រីនេត្រ \n","\n","KCC: សា - ស្ត្រា - ត្រី - នេ - ត្រ \n","\n","\n","Our implementation of KCC is a lot simpler than the rule. We just find the beginning of the character which is either C or I that does not follow by COEUNG."]},{"cell_type":"markdown","metadata":{"id":"xZFJSSHDIgKw","colab_type":"text"},"source":["## Results and Analysis"]},{"cell_type":"markdown","metadata":{"id":"m3XzV4S7ngMt","colab_type":"text"},"source":["\n","\n","Comparison:\n","Vichet Chear paper has more features:\n","- prefix, suffix, compound word notation\n","This means the algorithm has predicts more set of classes (more possible outcomes).\n","\n","we don't have any extra notation so our labels is just 2 classes 0 or 1 which is enough for our purpose.\n","\n","\n","More domain data such as: religious domain, economic, and medical. Our training and test set are all from one news domain even though it cover variety of topics.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JzK4C8mzIwWy","colab_type":"text"},"source":["### KCC vs Character based\n","Here we try to compare the result using KCC and Character based.\n","The accuracy result on test set for KCC is lower than character based:\n","- 97.37% for KCC\n","- 97.5% for Character\n","\n","This is because KCC has lower number of tokens so ratio of correct/incorrect is lower. By looking at word accuracy, we see that KCC does perform better:\n","- 96.87% for KCC\n","- 95.37% for character\n","\n","Word accuracy is a better comparison since the ratio is of the same scale. Thus we choose KCC for the full dataset training.\n","\n","The KCC approach able to learn very fast where the training set result if almost perfect with 0.9997 and character approach is 0.987. KCC has more possible state (combination of different characters --1836  kcc) where character approach is only 176 different characters.  \n"]},{"cell_type":"markdown","metadata":{"id":"M3vqdV_GM5kR","colab_type":"text"},"source":["#### Detail result for KCC vs Character based"]},{"cell_type":"markdown","metadata":{"id":"7mY0ZCgEMQuF","colab_type":"text"},"source":["KCC based\n","```\n","=== Training set performance === \n","total kcc: 57964  total word: 24704\n","correct kcc:57950  incorrect kcc: 14  kcc accuracy: 0.999758\n","correct word:24695  missed word: 9 word accuracy: 0.999635\n","Precision:\t0.999797\n","Recall:\t\t0.999635\n","Accuracy:\t0.999758\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     33260\n","           1       1.00      1.00      1.00     24704\n","\n","    accuracy                           1.00     57964\n","   macro avg       1.00      1.00      1.00     57964\n","weighted avg       1.00      1.00      1.00     57964\n","\n","\n","=== Test set performance === \n","total kcc: 15271  total word: 6512\n","correct kcc: 14870  incorrect kcc: 401  kcc accuracy: 0.973741\n","correct word: 6308  missed word: 204 word accuracy: 0.968673\n","Precision: 0.969715\n","Recall:    0.968673\n","Accuracy:  0.973741\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98      8759\n","           1       0.97      0.97      0.97      6512\n","\n","    accuracy                           0.97     15271\n","   macro avg       0.97      0.97      0.97     15271\n","weighted avg       0.97      0.97      0.97     15271\n","\n","```\n","\n","Character Based\n","\n","```\n","Training set --------------- \n","size of input: 800\n","Total char: 125974  total word: 26727\n","correct char:124416  incorrect: 1558 char accuracy: 0.9876323685839935\n","correct word:26022  missed word: 705 word accuracy: 0.9736221798181615\n","n_edit: 1553  acc: 0.9876720593138266\n","Precision:\t0.9682604651162791\n","Recall:\t\t0.9736221798181615\n","Accuracy:\t0.9876323685839935\n","\n","Test set --------------- \n","size of input: 108\n","Total char: 16946  total word: 3605\n","correct char:16526  incorrect: 420 char accuracy: 0.9752153900625516\n","correct word:3438  missed word: 167 word accuracy: 0.9536754507628294\n","n_edit: 419  acc: 0.9752744010385932\n","Precision:\t0.9314548902736386\n","Recall:\t\t0.9536754507628294\n","Accuracy:\t0.9752153900625516\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"GJOEDdcSNYHV","colab_type":"text"},"source":["### Comparing the Final Result"]},{"cell_type":"markdown","metadata":{"id":"OX7xjRF2L-PD","colab_type":"text"},"source":["Here we will analyze the result in comparison to the latest state of the art from Vichet Chea et al. Our implementation here has an error rate of 0.3% while the performance from Vichet Chear et al. [2] is 98.5% accuracy or 1.5% error rate. \n","\n","Our implementation is significantly better in term of performance but our implementation only considers 2 tags (1: a beginning of a word, 0: otherwise) while Vichet Chea et al. [2] has 5 different tags to distinguish the prefix, suffix and compound word. So there are more options for the algorithm in [2] to learn and predict thus it is much harder.\n","\n","Although, [2] shows the experiment result on 2 tags vs 5 tags has a very similar F-score implying that performance are not too different.\n","\n","Also note that the accuracy for paper is based on number of correct characters over total number of characters while our implementation is based on KCC.\n"]},{"cell_type":"markdown","metadata":{"id":"BpAAtNNTMJ4V","colab_type":"text"},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{"id":"FpC4aLQQJ4l6","colab_type":"text"},"source":["We compared KCC vs character based implementation and choose KCC for better word accuracy.\n","\n","We cover steps to fine tune the hyper parameter. We did a few options for different features but we did not show all the steps. But shorten the key is one main approach to save memory for training.\n","\n","We are able to achieve a 0.3% error rate."]},{"cell_type":"markdown","metadata":{"id":"ILBGp8yspB_y","colab_type":"text"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"IrQszqbUIU7t","colab_type":"text"},"source":["### Source\n","\n","\n","Data:\n","- bible word breaking: https://github.com/silnrsi/khmerlbdict --has sealang freq word: http://sealang.net/project/list/\n","- using tries: https://viblo.asia/p/nlp-khmer-word-segmentation-YWOZrgNNlQ0\n","- https://github.com/RathanakSreang/KhmerWordSegmentation\n","\n","CFR Paper\n","* https://www.research.ed.ac.uk/portal/files/10482724/crftut_fnt.pdf\n","An Introduction to Conditional Random Fields, Sutton, C & McCallum\n","* https://github.com/wukuun/crf/blob/master/crfpaper/crf_klinger_tomanek.pdf\n","* http://www.albertauyeung.com/post/python-sequence-labelling-with-crf/\n","* https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513\n","  * https://github.com/FelixMohr/NLP-with-Python\n","  * word seg: https://github.com/FelixMohr/NLP-with-Python/blob/master/CRFs-latin-word-segmenation.ipynb\n","* simple crf implementation:  https://github.com/timvieira/crf/tree/master/crf\n","* http://alias-i.com/lingpipe/demos/tutorial/crf/read-me.html\n","\n","Khmer References\n","* Vichet Chea, Ye Kyaw Thu, Chenchen Ding, Masao Utiyama, Andrew Finch, Eiichiro Sumita. Khmer Word Segmentation Using Conditional Random Fields. Research and Development Center, NIPTICT, Phnom Penh, Cambodia. Dec 2015. https://pdfs.semanticscholar.org/818e/213b403d6c8382fab6dd67d2679ef198d334.pdf\n","* Chea Sok Huor, Top Rithy, Ros Pich Hemy, Vann Navy, “Word Bigram Vs Orthographic Syllable Bigram in Khmer Word Segmentation” http://ww.panl10n.net/english/final%20reports/pdf%20files/Cambodia/CAM05.pdf\n","* A Large-scale Study of Statistical Machine Translation Methods\n","for Khmer Language: https://www.aclweb.org/anthology/Y15-1030 (Ye Kyaw Thu, Vichet Chea)\n","\n"]}]}